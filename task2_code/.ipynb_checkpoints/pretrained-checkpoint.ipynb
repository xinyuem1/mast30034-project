{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.models import Model\n",
    "from keras.layers import Input,Conv2D,MaxPooling2D,Dropout,UpSampling2D,concatenate,BatchNormalization,Add,Activation\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale = 1/255.0,\n",
    "        zca_epsilon=1e-06,\n",
    "        rotation_range=90,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        brightness_range=[0.9,1.1],\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        channel_shift_range=0.0,\n",
    "        fill_mode=\"nearest\",\n",
    "        horizontal_flip=False,\n",
    "        vertical_flip=False,\n",
    "        preprocessing_function=None,\n",
    "        data_format=None,\n",
    "        validation_split=0.0,\n",
    "        dtype=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "df =pd.read_csv(\"../HAM10000_metadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df, df, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[['dx_type','sex','localization']].to_csv('meta_train.csv')\n",
    "X_test[['dx_type','sex','localization']].to_csv('meta_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_datagen = ImageDataGenerator(rescale = 1/255.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6710 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'train',\n",
    "    batch_size = 64,\n",
    "    target_size=(128,128),\n",
    "    class_mode = 'categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3305 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "val_generator = val_datagen.flow_from_directory(\n",
    "        'val',\n",
    "    batch_size = 32,\n",
    "    target_size=(128,128),\n",
    "    class_mode = 'categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### inception\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "Inception_model = InceptionV3(input_shape = (128, 128, 3), include_top = False, weights = 'imagenet')\n",
    "x = layers.Flatten()(Inception_model.output)\n",
    "x = layers.Dense(1024, activation='relu')(x)\n",
    "x = layers.Dropout(0.2)(x)\n",
    "x = layers.Dense(7, activation='sigmoid')(x)\n",
    "\n",
    "Inception_model = keras.models.Model(Inception_model.input, x)\n",
    "Inception_model.compile(optimizer= RMSprop(lr=0.0001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "105/105 [==============================] - 449s 4s/step - loss: 0.9374 - accuracy: 0.6854 - val_loss: 4.1513 - val_accuracy: 0.6660\n",
      "Epoch 2/10\n",
      "105/105 [==============================] - 128s 1s/step - loss: 0.7156 - accuracy: 0.7490 - val_loss: 3.0929 - val_accuracy: 0.6805\n",
      "Epoch 3/10\n",
      "105/105 [==============================] - 127s 1s/step - loss: 0.6188 - accuracy: 0.7791 - val_loss: 2.0171 - val_accuracy: 0.7023\n",
      "Epoch 4/10\n",
      "105/105 [==============================] - 128s 1s/step - loss: 0.5574 - accuracy: 0.7999 - val_loss: 1.3841 - val_accuracy: 0.7498\n",
      "Epoch 5/10\n",
      "105/105 [==============================] - 133s 1s/step - loss: 0.5011 - accuracy: 0.8162 - val_loss: 1.6884 - val_accuracy: 0.7598\n",
      "Epoch 6/10\n",
      "105/105 [==============================] - 142s 1s/step - loss: 0.4696 - accuracy: 0.8301 - val_loss: 2.2009 - val_accuracy: 0.7443\n",
      "Epoch 7/10\n",
      "105/105 [==============================] - 138s 1s/step - loss: 0.4304 - accuracy: 0.8440 - val_loss: 2.2707 - val_accuracy: 0.7498\n",
      "Epoch 8/10\n",
      "105/105 [==============================] - 133s 1s/step - loss: 0.4017 - accuracy: 0.8528 - val_loss: 1.4475 - val_accuracy: 0.7900\n",
      "Epoch 9/10\n",
      "105/105 [==============================] - 132s 1s/step - loss: 0.3745 - accuracy: 0.8686 - val_loss: 1.6483 - val_accuracy: 0.7776\n",
      "Epoch 10/10\n",
      "105/105 [==============================] - 131s 1s/step - loss: 0.3565 - accuracy: 0.8702 - val_loss: 1.3425 - val_accuracy: 0.7967\n"
     ]
    }
   ],
   "source": [
    "Incephist = Inception_model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "  epochs=10,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Inception_model.save('inception.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_df = pd.DataFrame(Incephist.history) \n",
    "\n",
    "hist_csv_file = 'Incephist.csv'\n",
    "with open(hist_csv_file, mode='w') as f:\n",
    "    hist_df.to_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "105/105 [==============================] - 377s 4s/step - loss: 1.0518 - accuracy: 0.6648 - val_loss: 1.0334 - val_accuracy: 0.6660\n",
      "Epoch 2/10\n",
      "105/105 [==============================] - 360s 3s/step - loss: 0.8843 - accuracy: 0.6884 - val_loss: 0.8386 - val_accuracy: 0.7116\n",
      "Epoch 3/10\n",
      "105/105 [==============================] - 360s 3s/step - loss: 0.8131 - accuracy: 0.7116 - val_loss: 0.7546 - val_accuracy: 0.7262\n",
      "Epoch 4/10\n",
      "105/105 [==============================] - 360s 3s/step - loss: 0.7616 - accuracy: 0.7219 - val_loss: 0.7517 - val_accuracy: 0.7410\n",
      "Epoch 5/10\n",
      "105/105 [==============================] - 360s 3s/step - loss: 0.7128 - accuracy: 0.7402 - val_loss: 0.7284 - val_accuracy: 0.7325\n",
      "Epoch 6/10\n",
      "105/105 [==============================] - 360s 3s/step - loss: 0.6939 - accuracy: 0.7511 - val_loss: 0.6785 - val_accuracy: 0.7470\n",
      "Epoch 7/10\n",
      "105/105 [==============================] - 360s 3s/step - loss: 0.6656 - accuracy: 0.7584 - val_loss: 0.6545 - val_accuracy: 0.7570\n",
      "Epoch 8/10\n",
      "105/105 [==============================] - 360s 3s/step - loss: 0.6365 - accuracy: 0.7665 - val_loss: 0.6460 - val_accuracy: 0.7616\n",
      "Epoch 9/10\n",
      " 96/105 [==========================>...] - ETA: 20s - loss: 0.6165 - accuracy: 0.7740"
     ]
    }
   ],
   "source": [
    "### VGG16\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "VGG_model = VGG16(weights = 'imagenet', include_top = False, input_shape =(128,128,3))\n",
    "\n",
    "x = layers.Flatten()(VGG_model.output)\n",
    "x = layers.Dense(1024, activation='relu')(x)\n",
    "x = layers.Dropout(0.2)(x)\n",
    "x = layers.Dense(7, activation='sigmoid')(x)\n",
    "\n",
    "\n",
    "VGG_model = keras.models.Model(VGG_model.input, x)\n",
    "VGG_model.compile(optimizer= SGD(lr=0.005),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "VGG_hist = VGG_model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "  epochs=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "VGG_model.save('vgg.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_df = pd.DataFrame(VGG_hist.history) \n",
    "\n",
    "hist_csv_file = 'VGG_hist.csv'\n",
    "with open(hist_csv_file, mode='w') as f:\n",
    "    hist_df.to_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_model = load_model('my_res_unetpp.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segmented_rgb(image):\n",
    "    mask = segment_model.predict(np.expand_dims(image/255.0,axis = 0))\n",
    "    mask[mask>0.5]=1\n",
    "    mask[mask<=0.5] = 0\n",
    "    new_image = image/255.0*np.repeat(mask,3,axis=3)\n",
    "    return new_image[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(\"seg_train\")\n",
    "nv = os.path.join('seg_train', 'nv')\n",
    "os.mkdir(nv)\n",
    "mel = os.path.join('seg_train', 'mel')\n",
    "os.mkdir(mel)\n",
    "bkl = os.path.join('seg_train', 'bkl')\n",
    "os.mkdir(bkl)\n",
    "bcc = os.path.join('seg_train', 'bcc')\n",
    "os.mkdir(bcc)\n",
    "akiec = os.path.join('seg_train', 'akiec')\n",
    "os.mkdir(akiec)\n",
    "vasc = os.path.join('seg_train', 'vasc')\n",
    "os.mkdir(vasc)\n",
    "df = os.path.join('seg_train', 'df')\n",
    "os.mkdir(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_list = ['mel','bkl','bcc','akiec','vasc','df', 'nv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in class_list:\n",
    "    for i in os.listdir(f'train/{j}'):\n",
    "        image = np.asarray(Image.open(f\"train/{j}/{i}\").resize((128,128)))\n",
    "        seg_image = segmented_rgb(image)\n",
    "        im = Image.fromarray((seg_image * 255.0).astype(np.uint8))\n",
    "        im.save(f'seg_train/{j}/{i}', 'JPEG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(\"seg_val\")\n",
    "nv = os.path.join('seg_val', 'nv')\n",
    "os.mkdir(nv)\n",
    "mel = os.path.join('seg_val', 'mel')\n",
    "os.mkdir(mel)\n",
    "bkl = os.path.join('seg_val', 'bkl')\n",
    "os.mkdir(bkl)\n",
    "bcc = os.path.join('seg_val', 'bcc')\n",
    "os.mkdir(bcc)\n",
    "akiec = os.path.join('seg_val', 'akiec')\n",
    "os.mkdir(akiec)\n",
    "vasc = os.path.join('seg_val', 'vasc')\n",
    "os.mkdir(vasc)\n",
    "df = os.path.join('seg_val', 'df')\n",
    "os.mkdir(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in class_list:\n",
    "    for i in os.listdir(f'val/{j}'):\n",
    "        image = np.asarray(Image.open(f\"val/{j}/{i}\").resize((128,128)))\n",
    "        seg_image = segmented_rgb(image)\n",
    "        im = Image.fromarray((seg_image * 255.0).astype(np.uint8))\n",
    "        im.save(f'seg_val/{j}/{i}', 'JPEG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_name = []\n",
    "labels = []\n",
    "for j in class_list:\n",
    "    for i in os.listdir(f'train/{j}'):\n",
    "        image_name.append(f'train/{j}/{i}')\n",
    "        labels.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'image_name':image_name, 'labels':labels})\n",
    "df['rgb'] = df['image_name'].map(lambda x: np.asarray(Image.open(x).resize((128,128))))\n",
    "rgb = np.array(df['rgb'].tolist())/255.0\n",
    "np.save(\"rgb_train\", rgb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['labels'].to_csv('labels_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_name = []\n",
    "labels = []\n",
    "for j in class_list:\n",
    "    for i in os.listdir(f'val/{j}'):\n",
    "        image_name.append(f'val/{j}/{i}')\n",
    "        labels.append(j)\n",
    "\n",
    "df = pd.DataFrame({'image_name':image_name, 'labels':labels})\n",
    "df['rgb'] = df['image_name'].map(lambda x: np.asarray(Image.open(x).resize((128,128))))\n",
    "rgb = np.array(df['rgb'].tolist())/255.0\n",
    "np.save(\"rgb_val\", rgb)\n",
    "df['labels'].to_csv('labels_val.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6714 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'seg_train',\n",
    "    batch_size = 64,\n",
    "    target_size=(128,128),\n",
    "    class_mode = 'categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3305 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "val_generator = val_datagen.flow_from_directory(\n",
    "        'seg_val',\n",
    "    batch_size = 32,\n",
    "    target_size=(128,128),\n",
    "    class_mode = 'categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "### inception\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "Inception_model_seg = InceptionV3(input_shape = (128, 128, 3), include_top = False, weights = 'imagenet')\n",
    "x = layers.Flatten()(Inception_model.output)\n",
    "x = layers.Dense(1024, activation='relu')(x)\n",
    "x = layers.Dropout(0.2)(x)\n",
    "x = layers.Dense(7, activation='sigmoid')(x)\n",
    "\n",
    "Inception_model_seg = keras.models.Model(Inception_model.input, x)\n",
    "Inception_model_seg.compile(optimizer= RMSprop(lr=0.0001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "105/105 [==============================] - 35s 332ms/step - loss: 1.6218 - accuracy: 0.6498 - val_loss: 1.4188 - val_accuracy: 0.6660\n",
      "Epoch 2/10\n",
      "105/105 [==============================] - 33s 312ms/step - loss: 1.2302 - accuracy: 0.6708 - val_loss: 1.0832 - val_accuracy: 0.6660\n",
      "Epoch 3/10\n",
      "105/105 [==============================] - 33s 312ms/step - loss: 0.9955 - accuracy: 0.6708 - val_loss: 0.9637 - val_accuracy: 0.6660\n",
      "Epoch 4/10\n",
      "105/105 [==============================] - 32s 310ms/step - loss: 0.9092 - accuracy: 0.6708 - val_loss: 1.0712 - val_accuracy: 0.6660\n",
      "Epoch 5/10\n",
      "105/105 [==============================] - 33s 313ms/step - loss: 0.8661 - accuracy: 0.6769 - val_loss: 0.8948 - val_accuracy: 0.6971\n",
      "Epoch 6/10\n",
      "105/105 [==============================] - 33s 312ms/step - loss: 0.8347 - accuracy: 0.6942 - val_loss: 0.9752 - val_accuracy: 0.6811\n",
      "Epoch 7/10\n",
      "105/105 [==============================] - 33s 310ms/step - loss: 0.8080 - accuracy: 0.6997 - val_loss: 0.9179 - val_accuracy: 0.6896\n",
      "Epoch 8/10\n",
      "105/105 [==============================] - 33s 312ms/step - loss: 0.7673 - accuracy: 0.7115 - val_loss: 0.8277 - val_accuracy: 0.7144\n",
      "Epoch 9/10\n",
      "105/105 [==============================] - 32s 309ms/step - loss: 0.7437 - accuracy: 0.7154 - val_loss: 0.8058 - val_accuracy: 0.7116\n",
      "Epoch 10/10\n",
      "105/105 [==============================] - 33s 315ms/step - loss: 0.7076 - accuracy: 0.7389 - val_loss: 0.7860 - val_accuracy: 0.7377\n"
     ]
    }
   ],
   "source": [
    "Incephist_seg = Inception_model_seg.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "  epochs=10,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "Inception_model_seg.save('inception_seg.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_df = pd.DataFrame(Incephist_seg.history) \n",
    "\n",
    "hist_csv_file = 'Incephist_seg.csv'\n",
    "with open(hist_csv_file, mode='w') as f:\n",
    "    hist_df.to_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "105/105 [==============================] - 371s 4s/step - loss: 1.8734 - accuracy: 0.6200 - val_loss: 1.7783 - val_accuracy: 0.6660\n",
      "Epoch 2/10\n",
      "105/105 [==============================] - 360s 3s/step - loss: 1.7039 - accuracy: 0.6708 - val_loss: 1.6422 - val_accuracy: 0.6660\n",
      "Epoch 3/10\n",
      "105/105 [==============================] - 360s 3s/step - loss: 1.5908 - accuracy: 0.6708 - val_loss: 1.5436 - val_accuracy: 0.6660\n",
      "Epoch 4/10\n",
      "105/105 [==============================] - 360s 3s/step - loss: 1.4991 - accuracy: 0.6708 - val_loss: 1.4566 - val_accuracy: 0.6660\n",
      "Epoch 5/10\n",
      "105/105 [==============================] - 360s 3s/step - loss: 1.4150 - accuracy: 0.6708 - val_loss: 1.3756 - val_accuracy: 0.6660\n",
      "Epoch 6/10\n",
      "105/105 [==============================] - 360s 3s/step - loss: 1.3370 - accuracy: 0.6708 - val_loss: 1.3010 - val_accuracy: 0.6660\n",
      "Epoch 7/10\n",
      "105/105 [==============================] - 360s 3s/step - loss: 1.2660 - accuracy: 0.6708 - val_loss: 1.2322 - val_accuracy: 0.6660\n",
      "Epoch 8/10\n",
      "105/105 [==============================] - 360s 3s/step - loss: 1.1985 - accuracy: 0.6708 - val_loss: 1.1673 - val_accuracy: 0.6660\n",
      "Epoch 9/10\n",
      "105/105 [==============================] - 360s 3s/step - loss: 1.1383 - accuracy: 0.6708 - val_loss: 1.1053 - val_accuracy: 0.6660\n",
      "Epoch 10/10\n",
      "105/105 [==============================] - 360s 3s/step - loss: 1.0817 - accuracy: 0.6708 - val_loss: 1.0674 - val_accuracy: 0.6660\n"
     ]
    }
   ],
   "source": [
    "### VGG16\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "VGG_model_seg = VGG16(weights = 'imagenet', include_top = False, input_shape =(128,128,3))\n",
    "\n",
    "x = layers.Flatten()(VGG_model.output)\n",
    "x = layers.Dense(1024, activation='relu')(x)\n",
    "x = layers.Dropout(0.2)(x)\n",
    "x = layers.Dense(7, activation='sigmoid')(x)\n",
    "\n",
    "\n",
    "VGG_model_seg = keras.models.Model(VGG_model.input, x)\n",
    "VGG_model_seg.compile(optimizer= SGD(lr=0.005),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "VGG_hist_seg = VGG_model_seg.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "  epochs=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "VGG_model_seg.save('vgg_seg.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_df = pd.DataFrame(VGG_hist_seg.history) \n",
    "\n",
    "hist_csv_file = 'Incephist_seg.csv'\n",
    "with open(hist_csv_file, mode='w') as f:\n",
    "    hist_df.to_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_name = []\n",
    "labels = []\n",
    "for j in class_list:\n",
    "    for i in os.listdir(f'seg_train/{j}'):\n",
    "        image_name.append(f'seg_train/{j}/{i}')\n",
    "        labels.append(j)\n",
    "df = pd.DataFrame({'image_name':image_name, 'labels':labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[df['image_name'] != 'seg_train/mel/.ipynb_checkpoints']\n",
    "df['rgb'] = df['image_name'].map(lambda x: np.asarray(Image.open(x).resize((128,128))))\n",
    "rgb = np.array(df['rgb'].tolist())/255.0\n",
    "np.save(\"rgb_train_seg\", rgb)\n",
    "df['labels'].to_csv('labels_train_seg.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_name = []\n",
    "labels = []\n",
    "for j in class_list:\n",
    "    for i in os.listdir(f'seg_val/{j}'):\n",
    "        image_name.append(f'seg_val/{j}/{i}')\n",
    "        labels.append(j)\n",
    "df = pd.DataFrame({'image_name':image_name, 'labels':labels})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[df['image_name'] != 'seg_val/bkl/.ipynb_checkpoints']\n",
    "df['rgb'] = df['image_name'].map(lambda x: np.asarray(Image.open(x).resize((128,128))))\n",
    "rgb = np.array(df['rgb'].tolist())/255.0\n",
    "np.save(\"rgb_val_seg\", rgb)\n",
    "df['labels'].to_csv('labels_val_seg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('rgb_train_seg.npy')\n",
    "X_test = np.load('rgb_val_seg.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(pd.read_csv('labels_train_seg.csv')['labels'])\n",
    "y_test = np.array(pd.read_csv('labels_val_seg.csv')['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-2-3-gpu.2-3.m58",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-3-gpu.2-3:m58"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
